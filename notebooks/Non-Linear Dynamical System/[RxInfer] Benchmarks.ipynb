{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55f33945",
   "metadata": {},
   "source": [
    "This notebook performs a comprehensive becnhmark suit for the inference procedure for the double pendulum system using the RxInfer framework.\n",
    "\n",
    "_Author: Dmitry Bagaev_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f07b50d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "using DrWatson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b399d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "@quickactivate \"RxInferThesisExperiments\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ece426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "using RxInferThesisExperiments, RxInfer, StaticArrays, Plots, PGFPlotsX, LaTeXStrings\n",
    "using LinearAlgebra, StableRNGs, Random, BenchmarkTools, ColorSchemes, Dates, DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30e150a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/bvdmitri/.julia/dev/thesis/data/nlds/rxinfer\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const bfolder = datadir(\"nlds\", \"rxinfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97d0009c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pregenerate paths for benchmark data\n",
    "mkpath(bfolder);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd138f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DoublePendulum()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create default environment with default parameters\n",
    "const environment = DoublePendulum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1aab6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define state-transition function, uses RK4 method internally, see the `src/` folder\n",
    "f(state) = state_transition(environment)(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e37f8c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include the model specification\n",
    "include(srcdir(\"models\", \"rxinfer\", \"doublependulum.jl\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a2c016a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run_benchmark (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function run_benchmark(params)\n",
    "    @unpack T, niterations, seed = params\n",
    "    \n",
    "    states, observations = rand(StableRNG(seed), environment, T);\n",
    "    model    = double_pendulum(T)\n",
    "    result   = run_inference(model, observations; iterations = niterations)\n",
    "    e_states = extract_posteriors(T, result)\n",
    "    amse     = compute_amse(states, e_states)\n",
    "    \n",
    "    benchmark_modelcreation = @benchmark RxInfer.create_model(double_pendulum($T), \n",
    "        meta = double_pendulum_meta(), \n",
    "        constraints = double_pendulum_constraints(),\n",
    "    )\n",
    "    \n",
    "    benchmark_inference = @benchmark run_inference(model, observations; iterations = $niterations) setup=begin\n",
    "        model = double_pendulum($T)\n",
    "        states, observations = rand(StableRNG($seed), environment, $T);\n",
    "    end\n",
    "    \n",
    "    emse = compute_emse(seed) do _seed\n",
    "        local states, observations = rand(StableRNG(_seed), environment, T; random_start = true);\n",
    "        local model    = double_pendulum(T)\n",
    "        local result   = run_inference(model, observations; iterations = niterations)\n",
    "        local e_states = extract_posteriors(T, result)\n",
    "        return compute_amse(states, e_states)\n",
    "    end\n",
    "    \n",
    "    output = @strdict T niterations seed states e_states observations amse emse benchmark_modelcreation benchmark_inference\n",
    "    \n",
    "    return output\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82c8701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create a list of parameters we want to run our benchmarks with\n",
    "benchmark_params = dict_list(Dict(\n",
    "    \"T\"           => [ 10, 20, 30, 50, 100, 200, 300, 500, 1_000, 2_000, 5_000, 10_000, 20_000 ],\n",
    "    \"niterations\" => [ 3 ],\n",
    "    \"seed\"        => [ 42 ]\n",
    "));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c12cc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFile /Users/bvdmitri/.julia/dev/thesis/data/nlds/rxinfer/T=20000_niterations=3_seed=42.jld2 does not exist. Producing it now...\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFile /Users/bvdmitri/.julia/dev/thesis/data/nlds/rxinfer/T=20000_niterations=3_seed=42.jld2 saved.\n"
     ]
    }
   ],
   "source": [
    "# First run maybe slow, you may track the progress in the terminal\n",
    "# Subsequent runs will not create new benchmarks \n",
    "# but will reload it from data folder\n",
    "benchmarks = map(benchmark_params) do params\n",
    "    path = datadir(\"nlds\", \"rxinfer\")\n",
    "    result, _ = produce_or_load(run_benchmark, bfolder, params; tag = false, force = false)\n",
    "    return result\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5631ffe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mScanning folder /Users/bvdmitri/.julia/dev/thesis/data/nlds/rxinfer for result files.\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mAdded 22 entries.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>22×7 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">T</th><th style = \"text-align: left;\">seed</th><th style = \"text-align: left;\">niterations</th><th style = \"text-align: left;\">amse</th><th style = \"text-align: left;\">emse</th><th style = \"text-align: left;\">inference</th><th style = \"text-align: left;\">creation</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Union{Missing, Int64}\" style = \"text-align: left;\">Int64?</th><th title = \"Union{Missing, Int64}\" style = \"text-align: left;\">Int64?</th><th title = \"Union{Missing, Int64}\" style = \"text-align: left;\">Int64?</th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th><th title = \"Union{Missing, Tuple{Float64, Float64, Float64}}\" style = \"text-align: left;\">Tuple…?</th><th title = \"Union{Missing, Tuple{Float64, Float64, Float64}}\" style = \"text-align: left;\">Tuple…?</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">10</td><td style = \"text-align: right;\">42</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">8.09207</td><td style = \"text-align: right;\">7.10241</td><td style = \"text-align: left;\">(1.03787e6, 1.415e6, 0.0)</td><td style = \"text-align: left;\">(528773.0, 6.14133e5, 0.0)</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">10</td><td style = \"text-align: right;\">42</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">8.00521</td><td style = \"text-align: right;\">7.0327</td><td style = \"text-align: left;\">(1.23344e6, 1.88523e6, 0.0)</td><td style = \"text-align: left;\">(528994.0, 6.66653e5, 0.0)</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">20</td><td style = \"text-align: right;\">42</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">11.087</td><td style = \"text-align: right;\">12.1779</td><td style = \"text-align: left;\">(1.90448e6, 2.82422e6, 0.0)</td><td style = \"text-align: left;\">(1.00564e6, 1.20407e6, 0.0)</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">20</td><td style = \"text-align: right;\">42</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">10.8625</td><td style = \"text-align: right;\">12.0709</td><td style = \"text-align: left;\">(2.38106e6, 3.70301e6, 0.0)</td><td style = \"text-align: left;\">(1.02079e6, 1.41653e6, 0.0)</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">30</td><td style = \"text-align: right;\">42</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">9.23672</td><td style = \"text-align: right;\">6.52359</td><td style = \"text-align: left;\">(2.99427e6, 3.87393e6, 0.0)</td><td style = \"text-align: left;\">(1.49557e6, 1.90636e6, 0.0)</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: right;\">30</td><td style = \"text-align: right;\">42</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">9.04061</td><td style = \"text-align: right;\">6.45466</td><td style = \"text-align: left;\">(3.62919e6, 5.63203e6, 0.0)</td><td style = \"text-align: left;\">(1.54173e6, 1.96258e6, 0.0)</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: right;\">50</td><td style = \"text-align: right;\">42</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">7.23313</td><td style = \"text-align: right;\">3.52385</td><td style = \"text-align: left;\">(5.79057e6, 8.01622e6, 0.0)</td><td style = \"text-align: left;\">(2.81547e6, 3.22324e6, 0.0)</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: right;\">50</td><td style = \"text-align: right;\">42</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">7.21749</td><td style = \"text-align: right;\">3.54351</td><td style = \"text-align: left;\">(7.28601e6, 9.86715e6, 0.0)</td><td style = \"text-align: left;\">(2.5033e6, 3.32121e6, 0.0)</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: right;\">100</td><td style = \"text-align: right;\">42</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">4.16954</td><td style = \"text-align: right;\">1.28988</td><td style = \"text-align: left;\">(1.27809e7, 2.01602e7, 0.0)</td><td style = \"text-align: left;\">(5.83241e6, 7.28823e6, 0.0)</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: right;\">100</td><td style = \"text-align: right;\">42</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">4.15586</td><td style = \"text-align: right;\">1.28286</td><td style = \"text-align: left;\">(1.69376e7, 2.36152e7, 0.0)</td><td style = \"text-align: left;\">(5.83256e6, 7.14345e6, 0.0)</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: right;\">200</td><td style = \"text-align: right;\">42</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">0.84366</td><td style = \"text-align: right;\">0.617622</td><td style = \"text-align: left;\">(2.97711e7, 4.23667e7, 0.0)</td><td style = \"text-align: left;\">(1.17136e7, 1.48022e7, 0.0)</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: right;\">200</td><td style = \"text-align: right;\">42</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">0.843009</td><td style = \"text-align: right;\">0.615797</td><td style = \"text-align: left;\">(3.75334e7, 5.60961e7, 0.0)</td><td style = \"text-align: left;\">(1.1451e7, 1.40771e7, 0.0)</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: right;\">300</td><td style = \"text-align: right;\">42</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">1.39847</td><td style = \"text-align: right;\">0.480039</td><td style = \"text-align: left;\">(6.38084e7, 7.33319e7, 1.7617e7)</td><td style = \"text-align: left;\">(1.71523e7, 2.0527e7, 0.0)</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">14</td><td style = \"text-align: right;\">300</td><td style = \"text-align: right;\">42</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">1.38925</td><td style = \"text-align: right;\">0.478898</td><td style = \"text-align: left;\">(7.81838e7, 9.20168e7, 1.85378e7)</td><td style = \"text-align: left;\">(1.73351e7, 2.16345e7, 0.0)</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">15</td><td style = \"text-align: right;\">500</td><td style = \"text-align: right;\">42</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">0.367731</td><td style = \"text-align: right;\">0.41845</td><td style = \"text-align: left;\">(9.64137e7, 1.10284e8, 1.82263e7)</td><td style = \"text-align: left;\">(2.52241e7, 3.1052e7, 0.0)</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">16</td><td style = \"text-align: right;\">500</td><td style = \"text-align: right;\">42</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">0.365444</td><td style = \"text-align: right;\">0.417913</td><td style = \"text-align: left;\">(1.18881e8, 1.38779e8, 2.91914e7)</td><td style = \"text-align: left;\">(2.45217e7, 2.99869e7, 0.0)</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">17</td><td style = \"text-align: right;\">1000</td><td style = \"text-align: right;\">42</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">0.403539</td><td style = \"text-align: right;\">0.324854</td><td style = \"text-align: left;\">(1.90928e8, 2.39484e8, 4.88649e7)</td><td style = \"text-align: left;\">(5.07746e7, 6.41746e7, 0.0)</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">18</td><td style = \"text-align: right;\">1000</td><td style = \"text-align: right;\">42</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">0.402657</td><td style = \"text-align: right;\">0.324515</td><td style = \"text-align: left;\">(2.56925e8, 3.07301e8, 5.93254e7)</td><td style = \"text-align: left;\">(5.05669e7, 6.16034e7, 0.0)</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">19</td><td style = \"text-align: right;\">2000</td><td style = \"text-align: right;\">42</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">0.320011</td><td style = \"text-align: right;\">0.292229</td><td style = \"text-align: left;\">(4.27004e8, 5.24598e8, 1.11555e8)</td><td style = \"text-align: left;\">(1.21868e8, 1.45545e8, 0.0)</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">20</td><td style = \"text-align: right;\">5000</td><td style = \"text-align: right;\">42</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">0.273683</td><td style = \"text-align: right;\">0.298292</td><td style = \"text-align: left;\">(1.32178e9, 1.52093e9, 5.30091e8)</td><td style = \"text-align: left;\">(3.20467e8, 3.84349e8, 3.78359e7)</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">21</td><td style = \"text-align: right;\">10000</td><td style = \"text-align: right;\">42</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">0.298489</td><td style = \"text-align: right;\">0.296422</td><td style = \"text-align: left;\">(3.26564e9, 3.33524e9, 1.5786e9)</td><td style = \"text-align: left;\">(7.02109e8, 8.50678e8, 1.08506e8)</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">22</td><td style = \"text-align: right;\">20000</td><td style = \"text-align: right;\">42</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">0.275803</td><td style = \"text-align: right;\">0.284589</td><td style = \"text-align: left;\">(6.75628e9, 6.75628e9, 3.38926e9)</td><td style = \"text-align: left;\">(1.437e9, 1.69095e9, 2.53355e8)</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& T & seed & niterations & amse & emse & inference & \\\\\n",
       "\t\\hline\n",
       "\t& Int64? & Int64? & Int64? & Float64? & Float64? & Tuple…? & \\\\\n",
       "\t\\hline\n",
       "\t1 & 10 & 42 & 3 & 8.09207 & 7.10241 & (1.03787e6, 1.415e6, 0.0) & $\\dots$ \\\\\n",
       "\t2 & 10 & 42 & 5 & 8.00521 & 7.0327 & (1.23344e6, 1.88523e6, 0.0) & $\\dots$ \\\\\n",
       "\t3 & 20 & 42 & 3 & 11.087 & 12.1779 & (1.90448e6, 2.82422e6, 0.0) & $\\dots$ \\\\\n",
       "\t4 & 20 & 42 & 5 & 10.8625 & 12.0709 & (2.38106e6, 3.70301e6, 0.0) & $\\dots$ \\\\\n",
       "\t5 & 30 & 42 & 3 & 9.23672 & 6.52359 & (2.99427e6, 3.87393e6, 0.0) & $\\dots$ \\\\\n",
       "\t6 & 30 & 42 & 5 & 9.04061 & 6.45466 & (3.62919e6, 5.63203e6, 0.0) & $\\dots$ \\\\\n",
       "\t7 & 50 & 42 & 3 & 7.23313 & 3.52385 & (5.79057e6, 8.01622e6, 0.0) & $\\dots$ \\\\\n",
       "\t8 & 50 & 42 & 5 & 7.21749 & 3.54351 & (7.28601e6, 9.86715e6, 0.0) & $\\dots$ \\\\\n",
       "\t9 & 100 & 42 & 3 & 4.16954 & 1.28988 & (1.27809e7, 2.01602e7, 0.0) & $\\dots$ \\\\\n",
       "\t10 & 100 & 42 & 5 & 4.15586 & 1.28286 & (1.69376e7, 2.36152e7, 0.0) & $\\dots$ \\\\\n",
       "\t11 & 200 & 42 & 3 & 0.84366 & 0.617622 & (2.97711e7, 4.23667e7, 0.0) & $\\dots$ \\\\\n",
       "\t12 & 200 & 42 & 5 & 0.843009 & 0.615797 & (3.75334e7, 5.60961e7, 0.0) & $\\dots$ \\\\\n",
       "\t13 & 300 & 42 & 3 & 1.39847 & 0.480039 & (6.38084e7, 7.33319e7, 1.7617e7) & $\\dots$ \\\\\n",
       "\t14 & 300 & 42 & 5 & 1.38925 & 0.478898 & (7.81838e7, 9.20168e7, 1.85378e7) & $\\dots$ \\\\\n",
       "\t15 & 500 & 42 & 3 & 0.367731 & 0.41845 & (9.64137e7, 1.10284e8, 1.82263e7) & $\\dots$ \\\\\n",
       "\t16 & 500 & 42 & 5 & 0.365444 & 0.417913 & (1.18881e8, 1.38779e8, 2.91914e7) & $\\dots$ \\\\\n",
       "\t17 & 1000 & 42 & 3 & 0.403539 & 0.324854 & (1.90928e8, 2.39484e8, 4.88649e7) & $\\dots$ \\\\\n",
       "\t18 & 1000 & 42 & 5 & 0.402657 & 0.324515 & (2.56925e8, 3.07301e8, 5.93254e7) & $\\dots$ \\\\\n",
       "\t19 & 2000 & 42 & 3 & 0.320011 & 0.292229 & (4.27004e8, 5.24598e8, 1.11555e8) & $\\dots$ \\\\\n",
       "\t20 & 5000 & 42 & 3 & 0.273683 & 0.298292 & (1.32178e9, 1.52093e9, 5.30091e8) & $\\dots$ \\\\\n",
       "\t21 & 10000 & 42 & 3 & 0.298489 & 0.296422 & (3.26564e9, 3.33524e9, 1.5786e9) & $\\dots$ \\\\\n",
       "\t22 & 20000 & 42 & 3 & 0.275803 & 0.284589 & (6.75628e9, 6.75628e9, 3.38926e9) & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m22×7 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m T      \u001b[0m\u001b[1m seed   \u001b[0m\u001b[1m niterations \u001b[0m\u001b[1m amse      \u001b[0m\u001b[1m emse      \u001b[0m\u001b[1m inference           \u001b[0m ⋯\n",
       "     │\u001b[90m Int64? \u001b[0m\u001b[90m Int64? \u001b[0m\u001b[90m Int64?      \u001b[0m\u001b[90m Float64?  \u001b[0m\u001b[90m Float64?  \u001b[0m\u001b[90m Tuple…?             \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │     10      42            3   8.09207    7.10241   (1.03787e6, 1.415e6, ⋯\n",
       "   2 │     10      42            5   8.00521    7.0327    (1.23344e6, 1.88523e\n",
       "   3 │     20      42            3  11.087     12.1779    (1.90448e6, 2.82422e\n",
       "   4 │     20      42            5  10.8625    12.0709    (2.38106e6, 3.70301e\n",
       "   5 │     30      42            3   9.23672    6.52359   (2.99427e6, 3.87393e ⋯\n",
       "   6 │     30      42            5   9.04061    6.45466   (3.62919e6, 5.63203e\n",
       "   7 │     50      42            3   7.23313    3.52385   (5.79057e6, 8.01622e\n",
       "   8 │     50      42            5   7.21749    3.54351   (7.28601e6, 9.86715e\n",
       "   9 │    100      42            3   4.16954    1.28988   (1.27809e7, 2.01602e ⋯\n",
       "  10 │    100      42            5   4.15586    1.28286   (1.69376e7, 2.36152e\n",
       "  11 │    200      42            3   0.84366    0.617622  (2.97711e7, 4.23667e\n",
       "  12 │    200      42            5   0.843009   0.615797  (3.75334e7, 5.60961e\n",
       "  13 │    300      42            3   1.39847    0.480039  (6.38084e7, 7.33319e ⋯\n",
       "  14 │    300      42            5   1.38925    0.478898  (7.81838e7, 9.20168e\n",
       "  15 │    500      42            3   0.367731   0.41845   (9.64137e7, 1.10284e\n",
       "  16 │    500      42            5   0.365444   0.417913  (1.18881e8, 1.38779e\n",
       "  17 │   1000      42            3   0.403539   0.324854  (1.90928e8, 2.39484e ⋯\n",
       "  18 │   1000      42            5   0.402657   0.324515  (2.56925e8, 3.07301e\n",
       "  19 │   2000      42            3   0.320011   0.292229  (4.27004e8, 5.24598e\n",
       "  20 │   5000      42            3   0.273683   0.298292  (1.32178e9, 1.52093e\n",
       "  21 │  10000      42            3   0.298489   0.296422  (3.26564e9, 3.33524e ⋯\n",
       "  22 │  20000      42            3   0.275803   0.284589  (6.75628e9, 6.75628e\n",
       "\u001b[36m                                                               2 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort(prepare_benchmarks_table(bfolder), [ :T ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e815c8",
   "metadata": {},
   "source": [
    "# Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cb4dbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.9.0\n",
      "Commit 8e630552924 (2023-05-07 11:25 UTC)\n",
      "Platform Info:\n",
      "  OS: macOS (x86_64-apple-darwin22.4.0)\n",
      "  CPU: 12 × Intel(R) Core(TM) i7-8850H CPU @ 2.60GHz\n",
      "  WORD_SIZE: 64\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-14.0.6 (ORCJIT, skylake)\n",
      "  Threads: 2 on 12 virtual cores\n"
     ]
    }
   ],
   "source": [
    "versioninfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4c715ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1mProject\u001b[22m\u001b[39m RxInferThesisExperiments v1.0.0\n",
      "\u001b[32m\u001b[1mStatus\u001b[22m\u001b[39m `~/.julia/dev/thesis/Project.toml`\n",
      "  \u001b[90m[6e4b80f9] \u001b[39mBenchmarkTools v1.3.2\n",
      "  \u001b[90m[35d6a980] \u001b[39mColorSchemes v3.21.0\n",
      "  \u001b[90m[a93c6f00] \u001b[39mDataFrames v1.5.0\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[31c24e10] \u001b[39mDistributions v0.25.94\n",
      "  \u001b[90m[634d3b9d] \u001b[39mDrWatson v2.12.5\n",
      "  \u001b[90m[9fc3f58a] \u001b[39mForneyLab v0.12.0\n",
      "  \u001b[90m[f6369f11] \u001b[39mForwardDiff v0.10.35\n",
      "  \u001b[90m[7073ff75] \u001b[39mIJulia v1.24.0\n",
      "  \u001b[90m[b964fa9f] \u001b[39mLaTeXStrings v1.3.0\n",
      "  \u001b[90m[3bd65402] \u001b[39mOptimisers v0.2.18\n",
      "  \u001b[90m[8314cec4] \u001b[39mPGFPlotsX v1.6.0\n",
      "  \u001b[90m[e4faabce] \u001b[39mPProf v2.2.2\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[91a5bcdd] \u001b[39mPlots v1.38.12\n",
      "  \u001b[90m[37e2e3b7] \u001b[39mReverseDiff v1.14.6\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[86711068] \u001b[39mRxInfer v2.10.4\n",
      "  \u001b[90m[860ef19b] \u001b[39mStableRNGs v1.0.0\n",
      "  \u001b[90m[aedffcd0] \u001b[39mStatic v0.8.7\n",
      "  \u001b[90m[90137ffa] \u001b[39mStaticArrays v1.5.25\n",
      "  \u001b[90m[fce5fe82] \u001b[39mTuring v0.25.1\n",
      "  \u001b[90m[e88e6eb3] \u001b[39mZygote v0.6.61\n",
      "  \u001b[90m[37e2e46d] \u001b[39mLinearAlgebra\n",
      "  \u001b[90m[9a3f8284] \u001b[39mRandom\n",
      "\u001b[36m\u001b[1mInfo\u001b[22m\u001b[39m Packages marked with \u001b[32m⌃\u001b[39m have new versions available and may be upgradable.\n"
     ]
    }
   ],
   "source": [
    "] status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532a4155",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
