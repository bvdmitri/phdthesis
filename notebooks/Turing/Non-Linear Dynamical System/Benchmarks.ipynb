{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55f33945",
   "metadata": {},
   "source": [
    "This notebook performs a comprehensive becnhmark suit for the inference procedure for the double pendulum system using the RxInfer framework.\n",
    "\n",
    "_Author: Dmitry Bagaev_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f07b50d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "using DrWatson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b399d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "@quickactivate \"RxInferThesisExperiments\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ece426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "using RxInferThesisExperiments, Turing, StaticArrays, Plots, PGFPlotsX, LaTeXStrings, ReverseDiff\n",
    "using LinearAlgebra, StableRNGs, Random, BenchmarkTools, ColorSchemes, Dates, DataFrames, Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30e150a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/bvdmitri/.julia/dev/RxInferThesisExperiments/data/nlds/turing/nuts\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const bfolder = datadir(\"nlds\", \"turing\", \"nuts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97d0009c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pregenerate paths for benchmark data\n",
    "mkpath(bfolder);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd138f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DoublePendulum()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create default environment with default parameters\n",
    "const environment = DoublePendulum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1aab6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define state-transition function, uses RK4 method internally, see the `src/` folder\n",
    "f(state) = state_transition(environment)(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e37f8c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include the model specification\n",
    "include(srcdir(\"models\", \"turing\", \"doublependulum.jl\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a2c016a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run_benchmark (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function run_benchmark(params)\n",
    "    return with_logger(NullLogger()) do\n",
    "        @unpack T, nsamples, seed = params\n",
    "\n",
    "        states, observations = rand(StableRNG(seed), environment, T);\n",
    "        model    = double_pendulum(observations, T)\n",
    "        method   = NUTS()\n",
    "        result   = sample_inference(model, method = method, nsamples = nsamples, rng = StableRNG(seed))\n",
    "        e_states = extract_posteriors(T, result)\n",
    "        amse     = compute_amse(states, e_states)\n",
    "\n",
    "        benchmark_modelcreation = @benchmark double_pendulum($observations, $T)\n",
    "\n",
    "        benchmark_inference = @benchmark sample_inference(model, method = $method; nsamples = $nsamples, rng = StableRNG($seed)) setup=begin\n",
    "            states, observations = rand(StableRNG($seed), environment, $T);\n",
    "            model = double_pendulum(observations, $T)\n",
    "        end\n",
    "\n",
    "        emse = compute_emse(seed) do _seed\n",
    "            local states, observations = rand(StableRNG(_seed), environment, T; random_start = true);\n",
    "            local model    = double_pendulum(observations, T)\n",
    "            local method   = NUTS()\n",
    "            local result   = sample_inference(model, method = method, nsamples = nsamples, rng = StableRNG(_seed))\n",
    "            local e_states = extract_posteriors(T, result)\n",
    "            return compute_amse(states, e_states)\n",
    "        end\n",
    "\n",
    "        output = @strdict T nsamples seed states e_states observations amse emse benchmark_modelcreation benchmark_inference\n",
    "\n",
    "        return output\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82c8701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create a list of parameters we want to run our benchmarks with\n",
    "benchmark_params = dict_list(Dict(\n",
    "    \"T\"           => [ 10, 20, 30, 50, 100, 300 ],\n",
    "    \"nsamples\"    => [ 50, 100, 200 ],\n",
    "    \"seed\"        => [ 42 ]\n",
    "));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2bfc867",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m[Turing]: progress logging is disabled globally\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m[AdvancedVI]: global PROGRESS is set as false\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Disable turing's show progress as it hurts performance (a bit)\n",
    "Turing.setprogress!(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c12cc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First run maybe slow, you may track the progress in the terminal\n",
    "# Subsequent runs will not create new benchmarks \n",
    "# but will reload it from data folder\n",
    "benchmarks = map(benchmark_params) do params\n",
    "    result, _ = produce_or_load(run_benchmark, bfolder, params; tag = false, force = false)\n",
    "    return result\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5631ffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort(prepare_benchmarks_table(bfolder), [ :T, :nsamples ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e815c8",
   "metadata": {},
   "source": [
    "# Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb4dbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "versioninfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c715ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "] status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532a4155",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
