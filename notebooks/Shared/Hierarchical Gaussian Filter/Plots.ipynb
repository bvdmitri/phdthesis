{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c21f958",
   "metadata": {},
   "outputs": [],
   "source": [
    "using DrWatson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2622779",
   "metadata": {},
   "outputs": [],
   "source": [
    "@quickactivate \"RxInferThesisExperiments\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd01008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "using RxInferThesisExperiments, Plots, PGFPlotsX, LaTeXStrings\n",
    "using LinearAlgebra, StableRNGs, Random, BenchmarkTools, ColorSchemes, Dates, DataFrames\n",
    "\n",
    "import RxInfer, ReactiveMP, ForneyLab, Turing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0109ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pgfplotsx()\n",
    "\n",
    "# gr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d21657",
   "metadata": {},
   "outputs": [],
   "source": [
    "const outfolder = plotsdir(\"hgf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5db196",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkpath(outfolder);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6556ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "function analyze_benchmarks(filterfunction, bfolder)\n",
    "    benchmarks = prepare_benchmarks_table(bfolder);\n",
    "\n",
    "    # Select only a portion of benchmarks for plotting\n",
    "    filtered = filter(filterfunction, benchmarks)\n",
    "\n",
    "    sorted = sort(filtered, [ :T ])\n",
    "\n",
    "    # RxInfer includes the model creation time in it\n",
    "    inference = getindex.(sorted.inference, 1) .- getindex.(sorted.inference, 3)\n",
    "    creation  = getindex.(sorted.creation, 1) .- getindex.(sorted.creation, 3)\n",
    "\n",
    "    min_timing_range = min(minimum(inference), minimum(creation))\n",
    "    max_timing_range = max(maximum(inference), maximum(creation))\n",
    "\n",
    "    return sorted, (inference, creation), (min_timing_range, max_timing_range)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfcf1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_seed = 42\n",
    "target_niterations = 3\n",
    "target_nsamples = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e0153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rxifb, (rxi_inference, rxi_creation), (rxi_min_tr, rxi_max_tr) = analyze_benchmarks(datadir(\"hgf\", \"rxinfer\")) do r\n",
    "    return r[\"niterations\"] == target_niterations && r[\"seed\"] == target_seed\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6b47b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "flfb, (fl_inference, fl_creation), (fl_min_tr, fl_max_tr) = analyze_benchmarks(datadir(\"hgf\", \"forneylab\")) do r\n",
    "    return r[\"niterations\"] == target_niterations && r[\"seed\"] == target_seed\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133b64f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgfb, (tg_inference, tg_creation), (tg_min_tr, tg_max_tr) = analyze_benchmarks(datadir(\"hgf\", \"turing\", \"nuts\")) do r\n",
    "    return r[\"nsamples\"] == target_nsamples && r[\"seed\"] == target_seed\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceb9133",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timing_range = min(rxi_min_tr, fl_min_tr, tg_min_tr)\n",
    "max_timing_range = max(rxi_max_tr, fl_max_tr, tg_max_tr)\n",
    "\n",
    "timing_range = exp.(range(log(min_timing_range), log(max_timing_range); length = 10))\n",
    "sizes_range = sort(collect(union(rxifb.T, flfb.T, tgfb.T)))\n",
    "\n",
    "yticks = (timing_range, replace.(to_ms_str.(timing_range; digits = 0), \".0\" => \"\"))\n",
    "xticks = (sizes_range, string.(sizes_range))\n",
    "\n",
    "pfontsettings = (\n",
    "    titlefontsize=18,\n",
    "    guidefontsize=16,\n",
    "    tickfontsize=14,\n",
    "    legendfontsize=14,\n",
    "    legend_font_halign = :left\n",
    ")\n",
    "\n",
    "p = plot(\n",
    "    size = (800, 400),\n",
    "    yscale = :log10, xscale = :log10, yticks = yticks, xticks = xticks, \n",
    "    ylabel = \"Time (log-scale)\", xlabel = \"Number of observation (log-scale)\",\n",
    "    legend = :outerright;\n",
    "    pfontsettings...\n",
    ")\n",
    "\n",
    "p = plot!(p, rxifb.T, rxi_inference, label = \"Reactive MP ($(target_niterations) iterations)\", marker = :circle)\n",
    "p = plot!(p, flfb.T, fl_inference, label = \"Scheduled MP (inference, $(target_niterations) iterations)\", marker = :utriangle)\n",
    "p = plot!(p, flfb.T, fl_creation, label = \"Scheduled MP (compilation)\", marker = :rect)\n",
    "p = plot!(p, tgfb.T, tg_inference, label = \"NUTS ($target_nsamples)\", marker = :dtriangle)\n",
    "\n",
    "savefig(joinpath(outfolder, \"04-benchmark_comparison.tex\"))\n",
    "\n",
    "display(\"image/png\", p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
