
@inproceedings{senoz_switching_2021,
	title = {The {Switching} {Hierarchical} {Gaussian} {Filter}},
	doi = {10.1109/ISIT45174.2021.9518229},
	abstract = {In this paper we discuss variational message passing-based (VMP) inference in a switching Hierarchical Gaussian Filter (HGF). An HGF is a flexible hierarchical state space model that supports closed-form VMP-based approximate inference for tracking of both states and slowly time-varying parameters. Since natural signals often submit to regime-switching dynamics, there is a need for low-complexity closed-form inference in switching state space models. Here we extend the HGF model with parameter switching mechanics and derive closed-form VMP update rules for plug-in applications in factor graph-based models. These VMP rules support both tracking of latent variables and variational free energy as a model performance measure. We show that the switching HGF performs better than a non-switching HGF on modelling of a stock market data set.},
	booktitle = {2021 {IEEE} {International} {Symposium} on {Information} {Theory} ({ISIT})},
	author = {Şenöz, İsmail and Podusenko, Albert and Akbayrak, Semih and Mathys, Christoph and de Vries, Bert},
	month = jul,
	year = {2021},
	keywords = {Message passing, Inference algorithms, Hidden Markov models, Time series analysis, Switches, Market research, Minimization},
	pages = {1373--1378},
	file = {IEEE Xplore Abstract Record:/Users/apodusenko/Zotero/storage/QM6V2R97/9518229.html:text/html;IEEE Xplore Full Text PDF:/Users/apodusenko/Zotero/storage/H4GFWHT5/Şenöz et al. - 2021 - The Switching Hierarchical Gaussian Filter.pdf:application/pdf},
}

@inproceedings{semih_akbayrak_podusenkoakbayrak-2022-cdc_nodate,
	title = {{Message passing-Based} {System} {Identification} for {NARMAX} {Models}},
	abstract = {We present a Bayesian identification procedure for polynomial NARMAX models based on message passing on a factor graph. Our probabilistic perspective lets us treat the noise instances as latent random variables and infer posterior distributions. These have the structure of precision-weighted prediction errors, as opposed to the point prediction errors obtained by classical NARMAX estimators. We empirically show that precision-weighting improves the estimates of the coefficients and ultimately the performance of the model during 1-step ahead prediction and simulation.},
	booktitle = {2022 {IEEE} {Conference} on {Decision} and {Control} ({CDC})},
	language = {en},
	urldate = {2022-06-30},
    month = dec,
	year = {2022},
	author = {Podusenko, Albert and Akbayrak, Semih and Şenöz, İsmail and Schoukens, Maarten and Kouw, Wouter M.},
}

@inproceedings{yao_yes_2018,
	title = {Yes, but {Did} {It} {Work}?: {Evaluating} {Variational} {Inference}},
	shorttitle = {Yes, but {Did} {It} {Work}?},
	url = {https://proceedings.mlr.press/v80/yao18a.html},
	abstract = {While it’s always possible to compute a variational approximation to a posterior distribution, it can be difficult to discover problems with this approximation. We propose two diagnostic algorithms to alleviate this problem. The Pareto-smoothed importance sampling (PSIS) diagnostic gives a goodness of fit measurement for joint distributions, while simultaneously improving the error in the estimate. The variational simulation-based calibration (VSBC) assesses the average performance of point estimates.},
	language = {en},
	urldate = {2022-07-22},
	booktitle = {Proceedings of the 35th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Yao, Yuling and Vehtari, Aki and Simpson, Daniel and Gelman, Andrew},
	month = jul,
	year = {2018},
	note = {ISSN: 2640-3498},
	pages = {5581--5590},
}

@article{akbayrak_probabilistic_2022,
	title = {Probabilistic programming with stochastic variational message passing},
	volume = {148},
	issn = {0888-613X},
	url = {https://www.sciencedirect.com/science/article/pii/S0888613X22000950},
	doi = {10.1016/j.ijar.2022.06.006},
	abstract = {Stochastic approximation methods for variational inference have recently gained popularity in the probabilistic programming community since these methods are amenable to automation and allow online, scalable, and universal approximate Bayesian inference. Unfortunately, common Probabilistic Programming Languages (PPLs) with stochastic approximation engines lack the efficiency of message passing-based inference algorithms with deterministic update rules such as Belief Propagation (BP) and Variational Message Passing (VMP). Still, Stochastic Variational Inference (SVI) and Conjugate-Computation Variational Inference (CVI) provide principled methods to integrate fast deterministic inference techniques with broadly applicable stochastic approximate inference. Unfortunately, implementation of SVI and CVI necessitates manually driven variational update rules, which does not yet exist in most PPLs. In this paper, we cast SVI and CVI explicitly in a message passing-based inference context. We provide an implementation for SVI and CVI in ForneyLab, which is an automated message passing-based probabilistic programming package in the open source Julia language. Through a number of experiments, we demonstrate how SVI and CVI extends the automated inference capabilities of message passing-based probabilistic programming.},
	language = {en},
	urldate = {2022-07-22},
	journal = {International Journal of Approximate Reasoning},
	author = {Akbayrak, Semih and Şenöz, İsmail and Sarı, Alp and de Vries, Bert},
	month = sep,
	year = {2022},
	keywords = {Factor graphs, Message passing, Natural gradient descent, Probabilistic programming, Variational inference},
	pages = {235--252},
	file = {ScienceDirect Full Text PDF:/Users/apodusenko/Zotero/storage/Z5E6TXHL/Akbayrak et al. - 2022 - Probabilistic programming with stochastic variatio.pdf:application/pdf},
}

@inproceedings{kurihara_collapsed_2007,
	title = {Collapsed {Variational} {Dirichlet} {Process} {Mixture} {Models}},
	abstract = {A number of variational Bayesian approximations to the Dirichlet process (DP) mixture model are studied and a novel collapsed VB approximation where mixture weights are marginalized out is considered. Nonparametric Bayesian mixture models, in particular Dirichlet process (DP) mixture models, have shown great promise for density estimation and data clustering. Given the size of today's datasets, computational efficiency becomes an essential ingredient in the applicability of these techniques to real world data. We study and experimentally compare a number of variational Bayesian (VB) approximations to the DP mixture model. In particular we consider the standard VB approximation where parameters are assumed to be independent from cluster assignment variables, and a novel collapsed VB approximation where mixture weights are marginalized out. For both VB approximations we consider two different ways to approximate the DP, by truncating the stick-breaking construction, and by using a finite mixture model with a symmetric Dirichlet prior.},
	booktitle = {{IJCAI}},
	author = {Kurihara, Kenichi and Welling, M. and Teh, Y.},
	year = {2007},
	file = {Kurihara - Collapsed Variational Dirichlet Process Mixture Mo.pdf:/Users/apodusenko/Zotero/storage/WTAC79QT/Kurihara - Collapsed Variational Dirichlet Process Mixture Mo.pdf:application/pdf},
}

@misc{stephen_a_billings_nonlinear_2013,
	title = {Nonlinear {System} {Identification}: {NARMAX} {Methods} in the {Time}, {Frequency}, and {Spatio}-{Temporal} {Domains} {\textbar} {Wiley}},
	shorttitle = {Nonlinear {System} {Identification}},
	url = {https://www.wiley.com/en-us/Nonlinear+System+Identification%3A+NARMAX+Methods+in+the+Time%2C+Frequency%2C+and+Spatio+Temporal+Domains-p-9781119943594},
	abstract = {Nonlinear System Identification: NARMAX Methods in the Time, Frequency, and Spatio-Temporal Domains describes a comprehensive framework for the identification and analysis of nonlinear dynamic systems in the time, frequency, and spatio-temporal domains. This book is written with an emphasis on making the algorithms accessible so that they can be applied and used in practice. Includes coverage of: The NARMAX (nonlinear autoregressive moving average with exogenous inputs) model The orthogonal least squares algorithm that allows models to be built term by term where the error reduction ratio reveals the percentage contribution of each model term Statistical and qualitative model validation methods that can be applied to any model class Generalised frequency response functions which provide significant insight into nonlinear behaviours A completely new class of filters that can move, split, spread, and focus energy The response spectrum map and the study of sub harmonic and severely nonlinear systems Algorithms that can track rapid time variation in both linear and nonlinear systems The important class of spatio-temporal systems that evolve over both space and time Many case study examples from modelling space weather, through identification of a model of the visual processing system of fruit flies, to tracking causality in EEG data are all includedto demonstrate how easily the methods can be applied in practice and to show the insight that the algorithms reveal even for complex systems NARMAX algorithms provide a fundamentally different approach to nonlinear system identification and signal processing for nonlinear systems. NARMAX methods provide models that are transparent, which can easily be analysed, and which can be used to solve real problems. This book is intended for graduates, postgraduates and researchers in the sciences and engineering, and also for users from other fields who have collected data and who wish to identify models to help to understand the dynamics of their systems.},
	language = {en-us},
	urldate = {2022-07-26},
	journal = {Wiley.com},
	author = {{Stephen A. Billings}},
	year = {2013},
	file = {Billings - Nonlinear System Identification.pdf:/Users/apodusenko/Zotero/storage/YVXY95SU/Billings - Nonlinear System Identification.pdf:application/pdf;Snapshot:/Users/apodusenko/Zotero/storage/TUJAMUAU/Nonlinear+System+Identification+NARMAX+Methods+in+the+Time,+Frequency,+and+Spatio+Temporal+Doma.html:text/html},
}
